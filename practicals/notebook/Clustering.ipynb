{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering News Articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"Dataset/Data_Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.STORY=df.STORY.apply(lambda x:re.sub(r\"[^A-Za-z]\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(row):\n",
    "    tokens=row.split()\n",
    "    word_list=[]\n",
    "    for x in tokens:\n",
    "        x=porter.stem(x.lower())\n",
    "        if (x not in stop_words) and len(x)>2:\n",
    "            word_list.append(x.lower())\n",
    "    return (\" \".join(word_list))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['story']=df.STORY.apply(lambda x:clean_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "tf = vectorizer.fit_transform(df['story']).toarray()\n",
    "\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 4\n",
    "\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=4, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Document %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document 0 words</th>\n",
       "      <th>Document 1 words</th>\n",
       "      <th>Document 2 words</th>\n",
       "      <th>Document 3 words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>thi</td>\n",
       "      <td>smartphon</td>\n",
       "      <td>parti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>market</td>\n",
       "      <td>said</td>\n",
       "      <td>phone</td>\n",
       "      <td>bjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>said</td>\n",
       "      <td>user</td>\n",
       "      <td>camera</td>\n",
       "      <td>elect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thi</td>\n",
       "      <td>use</td>\n",
       "      <td>appl</td>\n",
       "      <td>congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>film</td>\n",
       "      <td>samsung</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>price</td>\n",
       "      <td>also</td>\n",
       "      <td>pro</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>compani</td>\n",
       "      <td>like</td>\n",
       "      <td>display</td>\n",
       "      <td>seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trade</td>\n",
       "      <td>app</td>\n",
       "      <td>iphon</td>\n",
       "      <td>modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bank</td>\n",
       "      <td>new</td>\n",
       "      <td>devic</td>\n",
       "      <td>minist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>growth</td>\n",
       "      <td>one</td>\n",
       "      <td>launch</td>\n",
       "      <td>poll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document 0 words Document 1 words Document 2 words Document 3 words\n",
       "0             year              thi        smartphon            parti\n",
       "1           market             said            phone              bjp\n",
       "2             said             user           camera            elect\n",
       "3              thi              use             appl         congress\n",
       "4            india             film          samsung             said\n",
       "5            price             also              pro            state\n",
       "6          compani             like          display             seat\n",
       "7            trade              app            iphon             modi\n",
       "8             bank              new            devic           minist\n",
       "9           growth              one           launch             poll"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing top 10 words of each document..  \n",
    "Document0:- **technology related**   \n",
    "Document1:- **Politics**  \n",
    "Document2:- **Mobile Phones**  \n",
    "Document3:- **Entertainment** (like movie..)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
